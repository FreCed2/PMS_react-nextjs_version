import logging
from sqlalchemy import func
from app.extensions.db import db
from app.models import Project
from app.tasks.models import Task

logger = logging.getLogger(__name__)  # Logger for this module


class TaskService:
    @staticmethod
    def filter_tasks(filters=None):
        """
        Dynamically filters tasks based on criteria provided in a dictionary, 
        with optimized loading for related models.
        
        Args:
            filters (dict): A dictionary of filtering criteria.
                Supported keys:
                - "is_archived" (bool): Filter by archived status.
                - "project_id" (int): Filter by project ID.
                - "task_type" (str): Filter by task type.
                - "completion_status" (str): Filter by completion status ("completed" or "incomplete").
                - "exclude_task_id" (int): Exclude a specific task by ID.
                - "search_term" (str): Perform a search on task names.
        
        Returns:
            Query: SQLAlchemy query object with filters applied.
        """
        # Start query with optimized loading of related models
        query = Task.query.options(
            db.joinedload(Task.project).joinedload(Project.contributors),  # Load project and its contributors
            db.joinedload(Task.contributor),  # Load task's assigned contributor
            db.joinedload(Task.children),     # Load child tasks
        )

        try:
            if filters:
                logger.debug(f"Applying filters: {filters}")

                # Apply filters for specific fields
                if "is_archived" in filters and filters["is_archived"] is not None:
                    query = query.filter(Task.is_archived == filters["is_archived"])
                
                if "project_id" in filters and filters["project_id"] is not None:
                    query = query.filter(Task.project_id == filters["project_id"])
                
                if "task_type" in filters and filters["task_type"]:
                    query = query.filter(Task.task_type == filters["task_type"])
                
                # Map for completion status filtering
                completion_status_map = {
                    "completed": True,
                    "incomplete": False
                }
                if "completion_status" in filters and filters["completion_status"] in completion_status_map:
                    query = query.filter(Task.completed == completion_status_map[filters["completion_status"]])
                
                if "exclude_task_id" in filters:
                    query = query.filter(Task.id != filters["exclude_task_id"])

                # Apply search filter if provided
                if "search_term" in filters and filters["search_term"]:
                    search_term = f"%{filters['search_term'].lower()}%"
                    query = query.filter(func.lower(Task.name).like(search_term))
                    
            # Fetch all tasks to verify relationships
            tasks = query.all()
            logger.debug([task.to_dict() for task in tasks])  # Verify relationships in serialized output

            # Log the resulting query
            logger.debug(f"Generated query: {str(query)}")
            return query
        
        except Exception as e:
            logger.error(f"Error during task filtering: {str(e)}")
            raise RuntimeError(f"Failed to filter tasks: {str(e)}") from e

    @staticmethod
    def calculate_total_story_points(project_id):
        """Calculates the total story points for a project."""
        return (
            db.session.query(db.func.coalesce(db.func.sum(Task.story_points), 0))
            .filter(Task.project_id == project_id)
            .scalar()
        )

    @staticmethod
    def calculate_completed_story_points(project_id):
        """Calculates the total completed story points for a project."""
        return (
            db.session.query(db.func.coalesce(db.func.sum(Task.story_points), 0))
            .filter(Task.project_id == project_id, Task.completed == True)
            .scalar()
        )

    @staticmethod
    def calculate_completion_percentage(project_id):
        """Calculates the completion percentage of a project."""
        total_points = TaskService.calculate_total_story_points(project_id)
        completed_points = TaskService.calculate_completed_story_points(project_id)
        return round((completed_points / total_points) * 100, 2) if total_points > 0 else 0

    @staticmethod
    def delete_project_and_tasks(project_id):
        """Deletes a project and all its associated tasks."""
        logger.info(f"Deleting project and its tasks: Project ID {project_id}")
        project_to_delete = Project.query.get_or_404(project_id)
        try:
            Task.query.filter_by(project_id=project_id).delete()
            db.session.delete(project_to_delete)
            db.session.commit()
            return True, f"Project {project_id} deleted successfully."
        except Exception as e:
            logger.error(f"Error deleting project: Project ID {project_id} - {e}")
            db.session.rollback()
            return False, str(e)

    @staticmethod
    def contributor_has_assigned_tasks(project_id, contributor_id, project_name, contributor_name):
        """Checks if a contributor has tasks assigned in a project."""
        task_count = Task.query.filter_by(
            project=project_id, contributor_id=contributor_id
        ).count()
        logger.info(
            f"Contributor {contributor_name} has {task_count} tasks in project {project_name}."
        )
        return task_count > 0
    
    @staticmethod
    def fetch_task_with_logging(task_id):
        """Helper function to fetch a task with logging."""
        logger.info(f"Fetching task with ID {task_id}")
        print(f"Task ID: {task_id}")  # Ensure it runs without errors
        task = Task.query.get(task_id)
        if not task:
            logger.warning(f"Task with ID {task_id} not found.")
        return task
    
    
    @staticmethod
    def archive_task(task, visited=None):
        """
        Archive a task and all its subtasks, preventing infinite recursion.
        
        Args:
            task (Task): The task to be archived.
            visited (set): A set of task IDs already processed (for recursion guard).
        """
        if visited is None:
            visited = set()
        
        logger.info(f"Archiving task ID {task.id}")
        
        # Prevent infinite recursion
        if task.id in visited:
            logger.warning(f"Detected circular reference with task ID {task.id}. Skipping.")
            return

        visited.add(task.id)  # Mark task as visited
        task.is_archived = True

        # Archive subtasks
        for subtask in Task.query.filter_by(parent_id=task.id).all():
            logger.info(f"Archiving subtask ID {subtask.id} of task ID {task.id}")
            TaskService.archive_task(subtask, visited)

        # Add task to session for commit
        db.session.add(task)
        
    @staticmethod
    def validate_hierarchy(task):
        """
        Validates the hierarchy of a task to ensure valid parent-child relationships.

        Args:
            task (Task): The task instance to validate.

        Raises:
            ValueError: If the hierarchy rules are violated.
        """
        logger.info(f"Validating hierarchy for Task {task.id}: {task.name}")

        # Skip validation if task_type or parent_id is None
        if not task.task_type or not task.parent_id:
            logger.debug("Skipping hierarchy validation: Missing task_type or parent_id.")
            return

        # Prevent querying for invalid parent_id
        if task.parent_id == task.id:
            logger.error(f"Task {task.id} cannot be its own parent.")
            raise ValueError("A task cannot be its own parent.")

        # Fetch parent task type
        parent_task_type = db.session.query(Task.task_type).filter_by(id=task.parent_id).scalar()
        if not parent_task_type:
            logger.error(f"Parent task {task.parent_id} does not exist.")
            raise ValueError("Parent task does not exist.")

        # Hierarchy rules
        logger.debug(f"Parent task {task.parent_id} type: {parent_task_type}")

        if task.task_type == "Epic" and task.parent_id:
            logger.error("Epics cannot have a parent task.")
            raise ValueError("Epics cannot have a parent task.")

        if task.task_type == "User Story" and parent_task_type != "Epic":
            logger.error("If a User Story has a parent, it must be an Epic.")
            raise ValueError("If a User Story has a parent, it must be an Epic.")

        if task.task_type == "Subtask" and parent_task_type != "User Story":
            logger.error("If a Subtask has a parent, it must be a User Story.")
            raise ValueError("If a Subtask has a parent, it must be a User Story.")

        logger.info(f"Hierarchy validation passed for Task {task.id}: {task.name}")
        
    @staticmethod
    def fetch_all_tasks(project_id):
        """
        Fetches all tasks for a specific project, including project, contributor, and child task relationships.

        Args:
            project_id (int): The ID of the project whose tasks need to be fetched.

        Returns:
            list: A list of Task objects with their relationships loaded.
        """
        try:
            logger.info(f"Fetching all tasks for project ID: {project_id}")
            tasks = (
                Task.query.options(
                    db.joinedload(Task.project),
                    db.joinedload(Task.contributor),
                    db.joinedload(Task.children)
                )
                .filter_by(project_id=project_id)
                .all()
            )
            logger.info(f"Fetched {len(tasks)} tasks for project ID: {project_id}")
            return tasks
        except Exception as e:
            logger.error(f"Error fetching tasks for project ID {project_id}: {e}")
            raise
    
    
    @staticmethod
    def fetch_all_tasks_as_dicts(filters=None):
        """
        Fetches a list of tasks based on optional filters and serializes them into dictionaries.

        Args:
            filters (dict, optional): A dictionary of filters to apply to the task query.

        Returns:
            list[dict]: A list of serialized task dictionaries.
        """
        logger.info("Fetching all tasks with optional filters.")
        
        # Build the query
        query = Task.query
        if filters:
            if "project_id" in filters:
                query = query.filter(Task.project_id == filters["project_id"])
            if "completed" in filters:
                query = query.filter(Task.completed == filters["completed"])
            if "task_type" in filters:
                query = query.filter(Task.task_type == filters["task_type"])

        # Execute the query and serialize the results
        tasks = query.all()
        logger.info(f"Fetched {len(tasks)} tasks.")
        return [task.to_dict() for task in tasks]
    
    @staticmethod
    def fetch_task_as_dict(task_id):
        """
        Fetches a task by ID and returns it as a dictionary.

        Args:
            task_id (int): The ID of the task to fetch.

        Returns:
            dict: A dictionary representation of the task.

        Raises:
            ValueError: If the task is not found.
        """
        logger.info(f"Fetching task with ID {task_id}.")
        
        # Fetch the task from the database
        task = Task.query.get(task_id)
        if not task:
            logger.error(f"Task with ID {task_id} not found.")
            raise ValueError(f"Task with ID {task_id} not found.")
        
        # Serialize the task using its to_dict method
        task_dict = task.to_dict()
        logger.info(f"Task with ID {task_id} fetched successfully.")
        return task_dict

    def to_dict(self):
        """
        Converts the Task object into a dictionary for JSON responses.

        Returns:
            dict: A dictionary representation of the Task object.
        """
        return {
            "id": self.id,
            "name": self.name,
            "description": self.description,
            "task_type": self.task_type,
            "is_archived": self.is_archived,
            "completed": self.completed,
            "parent_id": self.parent_id,
            "project_id": self.project_id,
            "project": self.project.name if self.project else "Unknown Project",  # Fetch project name
            "contributor_id": self.contributor_id,
            "story_points": self.story_points,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "updated_at": self.updated_at.isoformat() if self.updated_at else None,
        }
        
    @staticmethod
    def generate_page_numbers(current_page, total_pages, left_edge=1, right_edge=1, left_current=2, right_current=2):
        """
        Generates a list of page numbers for pagination, including ellipses.
        
        Args:
            current_page (int): The current page number.
            total_pages (int): Total number of pages.
            left_edge (int): Number of pages to show at the left edge.
            right_edge (int): Number of pages to show at the right edge.
            left_current (int): Number of pages to show to the left of the current page.
            right_current (int): Number of pages to show to the right of the current page.

        Returns:
            list: A list of page numbers or None for ellipses.
        """
        result = []
        last_page = 0

        for page_num in range(1, total_pages + 1):
            if (
                page_num <= left_edge or
                (page_num >= current_page - left_current and page_num <= current_page + right_current) or
                page_num > total_pages - right_edge
            ):
                if last_page + 1 != page_num:
                    result.append(None)  # Ellipsis
                result.append(page_num)
                last_page = page_num

        return result